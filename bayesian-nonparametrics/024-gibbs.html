<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DP: Collapsed Gibbs Sampling</title>
  <link rel="shortcut icon" href="/a9online/static/icons/favicon-pad.png">
  <link rel="stylesheet" href="/a9online/static/reset.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" />
  <link rel="stylesheet" href="/a9online/static/viewer-style.css" />
  <link rel="stylesheet" href="/a9online/static/content-style.css" />
  <link rel="stylesheet" href="/a9online/static/print-style.css" media="print" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"></script>
  <script src="/a9online/static/render-math.js"></script>
  <script src="/a9online/static/spoiler.js"></script>
</head>

<body onload="RENDER_MATH.render(document.body);">
  <div id="wrapper">
    <div id="content-frame">
      <div id="content-name">DP: Collapsed Gibbs Sampling</div>
      <div id="content">
<p><a href="/a9online/bayesian-nonparametrics/000-outline.html">‚Üê Back to Outline</a></p>
<h1 id="inference">Inference</h1>
<p>Given $x_1, \dots, x_N$, we would like to infer $z_1, \dots, z_N$. We can try</p>
<p>$$\prob{\Mb{z}\mid\Mb{x}} = \frac{\prob{\Mb{x}\mid\Mb{z}}\prob{\Mb{z}}}{\prob{\Mb{x}}}$$</p>
<p>However, enumerate all possible cluster configurations is intractable. So we need to approximate, and one way is to use MCMC.</p>
<p>In particular, we will use Gibbs sampling. The idea is to resample one $z_i$ at a time. To sample $z_i$ in the Chinese restaurant process viewpoint, move customer #$i$ to be the last customer (can do so because of exchangeability), and let the customer choose a table.</p>
<h1 id="collapsed-gibbs-sampling">Collapsed Gibbs Sampling</h1>
<svg width="220" height="175" stroke="black" fill="white">
<g transform="translate(100,20)"><circle r="16" fill="white"></circle><foreignObject x="-16" y="-16" width="32" height="32"><div style="line-height: 32px; text-align: center;">$\pi$</div></foreignObject></g>
<g transform="translate(65,50)"><rect x="0" y="0" width="70" height="120" fill="white"></rect><foreignObject x="0" y="0" width="70" height="120"><div style="display: table-cell; width: 70px; height: 120px; text-align: right; vertical-align: bottom; padding: 3px;">$N$</div></foreignObject></g>
<g transform="translate(145,50)"><rect x="0" y="0" width="70" height="60" fill="white"></rect><foreignObject x="0" y="0" width="70" height="60"><div style="display: table-cell; width: 70px; height: 60px; text-align: right; vertical-align: bottom; padding: 3px;">$\infty$</div></foreignObject></g>
<g transform="translate(40,20)"><rect x="-14" y="-14" width="28" height="28" fill="lightgray"></rect><foreignObject x="-14" y="-14" width="28" height="28"><div style="line-height: 28px; text-align: center;">$\alpha$</div></foreignObject></g>
<g transform="translate(100,80)"><circle r="16" fill="white"></circle><foreignObject x="-16" y="-16" width="32" height="32"><div style="line-height: 32px; text-align: center;">$z_i$</div></foreignObject></g>
<g transform="translate(100,140)"><circle r="16" fill="lightgray"></circle><foreignObject x="-16" y="-16" width="32" height="32"><div style="line-height: 32px; text-align: center;">$x_i$</div></foreignObject></g>
<g transform="translate(180,80)"><circle r="16" fill="white"></circle><foreignObject x="-16" y="-16" width="32" height="32"><div style="line-height: 32px; text-align: center;">$\theta_j$</div></foreignObject></g>
<g transform="translate(180,20)"><rect x="-14" y="-14" width="28" height="28" fill="lightgray"></rect><foreignObject x="-14" y="-14" width="28" height="28"><div style="line-height: 28px; text-align: center;">$\lambda$</div></foreignObject></g>
<g><line x1="54" y1="20" x2="84" y2="19.999999999999996" stroke="black"></line><polygon points="0,0 -6,3 -6,-3" stroke="none" fill="black" transform="translate(84,19.999999999999996) rotate(0)"></polygon></g>
<g><line x1="100" y1="36" x2="100" y2="64" stroke="black"></line><polygon points="0,0 -6,3 -6,-3" stroke="none" fill="black" transform="translate(100,64) rotate(90)"></polygon></g>
<g><line x1="100" y1="96" x2="100" y2="124" stroke="black"></line><polygon points="0,0 -6,3 -6,-3" stroke="none" fill="black" transform="translate(100,124) rotate(90)"></polygon></g>
<g><line x1="180" y1="34" x2="180" y2="64" stroke="black"></line><polygon points="0,0 -6,3 -6,-3" stroke="none" fill="black" transform="translate(180,64) rotate(90)"></polygon></g>
<g><line x1="167.2" y1="89.6" x2="112.8" y2="130.4" stroke="black"></line><polygon points="0,0 -6,3 -6,-3" stroke="none" fill="black" transform="translate(112.8,130.4) rotate(143.13010235415598)"></polygon></g>
</svg>

<p><strong><em>Input</em></strong> Current $\Mb{z}^{(t-1)}$ in Markov chain</p>
<p><strong><em>Output</em></strong> $\Mb{z}^{(t)}$</p>
<blockquote>
<ol>
<li>Pick a random permutation $\tau$ of $\set{1,\dots,N}$</li>
<li>For each $i\in\set{\tau(1),\dots,\tau(N)}$, resample $z_i$ as follows.<blockquote>
<p>a. Find the likelihoods:
$$\begin{aligned} f_j(x_i) &amp;= \prob{x_i\mid z_i = j, \text{other }x, \text{other }z,\lambda} \\ &amp;= \prob{x_i\mid \text{other }x\text{ in table }j, \lambda} \\ &amp;= \prob{x_i\mid \lambda^*} \\ f_\text{new}(x_i) &amp;= \prob{x_i\mid z_i = \text{new cluster},\text{other }x, \text{other }z,\lambda} \\ &amp;= \prob{x_i\mid \lambda}\end{aligned}$$
b. Sample new $z_i$ from the multinomial distribution:
$$\begin{aligned} \prob{z_i = j} &amp;\propto \crab{N_j\text{ not counting }z_i} f_j(x_i) \\ \prob{z_i = \text{new cluster}} &amp;\propto \alpha f_\text{new}(x_i) \end{aligned}$$
c. Clean up empty clusters and establish new clusters (by sampling new $\theta_j$)</p>
</blockquote>
</li>
<li>Return the new $\Mb{z}$</li>
</ol>
</blockquote>
<p><strong><em>Notes</em></strong></p>
<ul>
<li>To calculate $\prob{x_i \mid \lambda}$, use
  $$\int_\Theta \prob{x_i\mid\theta}\prob{\theta\mid\lambda}\,d\theta$$
  Since we have <strong>collapsed</strong> $\theta$ out, the algorithm is called <strong>collapsed Gibbs sampling</strong>.</li>
<li>We can convert $\prob{x_i\mid \text{other }x\text{ in table }j, \lambda}$ to $\prob{x_i\mid \lambda^*}$ for some $\lambda^*$ if $H$ is a conjugate prior of $F$.</li>
<li>We may also want to resample $\alpha$. For example, we can use the prior $\alpha \sim \Mr{Gamma}(a,b)$ and resample $\alpha^{(t)}$ independent from $\alpha^{(t-1)}$.</li>
</ul>

      </div>
      <div id="content-time">Exported: 2021-01-02T21:40:29.288879</div>
    </div>
  </div>
</body>

</html>
